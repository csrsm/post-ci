(window.webpackJsonp=window.webpackJsonp||[]).push([[17],{491:function(a,_,v){"use strict";v.r(_);var t=v(5),i=Object(t.a)({},(function(){var a=this,_=a.$createElement,v=a._self._c||_;return v("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[v("h2",{attrs:{id:"_1-数据仓库分层"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_1-数据仓库分层"}},[a._v("#")]),a._v(" 1.数据仓库分层")]),a._v(" "),v("img",{attrs:{src:a.$withBase("/img/bigdata/数仓分层.png"),alt:"单架构"}}),a._v(" "),v("p",[a._v("--------------------------------------------范式建模begin----------------------------------------------------------")]),a._v(" "),v("ol",[v("li",[v("p",[a._v("**ODS层（operational data source）：**操作数据层，直接存放业务系统抽取过来的数据，将不同业务系统中的数据汇聚在一起")])]),a._v(" "),v("li",[v("p",[a._v("**DW层（data warehouse）：**数据仓库，按照主题建立各种数据模型")])])]),a._v(" "),v("ul",[v("li",[a._v("**DWD层（data warehouse detail）：**数据明细层，保证数据质量，在ods的基础上对数据进行加工处理，提供更干净的数据\n--------------------------------------------范式建模bend----------------------------------------------------------")])]),a._v(" "),v("p",[a._v("--------------------------------------------维度建模begin----------------------------------------------------------")]),a._v(" "),v("ul",[v("li",[a._v("**DWM层（data warehouse middle）：**数据中间层，对通用的维度进行轻度聚合，计算相应的统计指标，方便复用")]),a._v(" "),v("li",[a._v("**DWS层（data warehouse service）：**数据服务层，按照主题业务组织主题宽表，用于OLAP分析")])]),a._v(" "),v("ol",{attrs:{start:"3"}},[v("li",[a._v("**DM层（data market）：**数据集市层，基于DW层的基础数据，整合汇总成分析某一个主题域的报表数据\n--------------------------------------------维度建模end----------------------------------------------------------")])]),a._v(" "),v("p",[v("strong",[a._v("分层的目的：")])]),a._v(" "),v("ol",[v("li",[a._v("清晰的数据结构")]),a._v(" "),v("li",[a._v("减少重复开发")]),a._v(" "),v("li",[a._v("统一数据出口")]),a._v(" "),v("li",[a._v("简化问题")])]),a._v(" "),v("h2",{attrs:{id:"_2-数据库-oltp与数据仓库的区别-olap"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_2-数据库-oltp与数据仓库的区别-olap"}},[a._v("#")]),a._v(" 2.数据库-OLTP与数据仓库的区别-OLAP")]),a._v(" "),v("table",[v("thead",[v("tr",[v("th",[a._v("功能")]),a._v(" "),v("th",[a._v("数据库")]),a._v(" "),v("th",[a._v("数据差仓库")])])]),a._v(" "),v("tbody",[v("tr",[v("td",[a._v("数据范围")]),a._v(" "),v("td",[a._v("当前状态数据")]),a._v(" "),v("td",[a._v("存储完整、反映历史变化数据")])]),a._v(" "),v("tr",[v("td",[a._v("数据变化")]),a._v(" "),v("td",[a._v("支持频繁的增删改查")]),a._v(" "),v("td",[a._v("可增加、查询、无更新、删除操作")])]),a._v(" "),v("tr",[v("td",[a._v("应用场景")]),a._v(" "),v("td",[a._v("面向业务交易流程")]),a._v(" "),v("td",[a._v("面向分析、侧重决策分析")])]),a._v(" "),v("tr",[v("td",[a._v("处理数据量")]),a._v(" "),v("td",[a._v("频繁、小批次、高并发、低延迟")]),a._v(" "),v("td",[a._v("非频繁、大批量、高吞吐、有延迟")])]),a._v(" "),v("tr",[v("td",[a._v("设计理论")]),a._v(" "),v("td",[a._v("遵循数据库三范式、避免冗余")]),a._v(" "),v("td",[a._v("违范式、适当冗余")])]),a._v(" "),v("tr",[v("td",[a._v("建模方式")]),a._v(" "),v("td",[a._v("ER实体关系建模（范式建模）")]),a._v(" "),v("td",[a._v("范式建模+维度建模")])])])]),a._v(" "),v("h2",{attrs:{id:"_3-大数据技术栈"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_3-大数据技术栈"}},[a._v("#")]),a._v(" 3.大数据技术栈")]),a._v(" "),v("h3",{attrs:{id:"_1-架构底层核心技术"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_1-架构底层核心技术"}},[a._v("#")]),a._v(" 1.架构底层核心技术：")]),a._v(" "),v("ol",[v("li",[a._v("JVM")]),a._v(" "),v("li",[a._v("多线程、高并发")]),a._v(" "),v("li",[a._v("IO")])]),a._v(" "),v("h3",{attrs:{id:"_2-数据采集体系技术"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_2-数据采集体系技术"}},[a._v("#")]),a._v(" 2.数据采集体系技术")]),a._v(" "),v("ol",[v("li",[a._v("sqoop")]),a._v(" "),v("li",[a._v("DataX")]),a._v(" "),v("li",[a._v("Kettle")]),a._v(" "),v("li",[a._v("Flume")]),a._v(" "),v("li",[a._v("Maxwell")]),a._v(" "),v("li",[a._v("Canal")]),a._v(" "),v("li",[a._v("Nifi")])]),a._v(" "),v("h3",{attrs:{id:"_3-中间件技术栈"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_3-中间件技术栈"}},[a._v("#")]),a._v(" 3.中间件技术栈")]),a._v(" "),v("ol",[v("li",[a._v("zookeeper 分布式协调服务")]),a._v(" "),v("li",[a._v("redis 分布式缓存")]),a._v(" "),v("li",[a._v("kafka 分布式消息系统")]),a._v(" "),v("li",[a._v("Pulsar 分布式消息系统")]),a._v(" "),v("li",[a._v("ELK stack 数据分析")])]),a._v(" "),v("h3",{attrs:{id:"_4-分布式存储"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_4-分布式存储"}},[a._v("#")]),a._v(" 4.分布式存储")]),a._v(" "),v("ol",[v("li",[a._v("HDFS 分布式文件系统")]),a._v(" "),v("li",[a._v("HBase 分布式数据库")]),a._v(" "),v("li",[a._v("Hive 分布式数仓")]),a._v(" "),v("li",[a._v("Hudi、Delta lack、Iceberg 数据湖技术")])]),a._v(" "),v("h3",{attrs:{id:"_5-数据处理技术"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_5-数据处理技术"}},[a._v("#")]),a._v(" 5.数据处理技术")]),a._v(" "),v("ol",[v("li",[a._v("MapReduce 分布式计算框架")]),a._v(" "),v("li",[a._v("Spark 分布式计算框架")]),a._v(" "),v("li",[a._v("Flink 分布式计算框架")])]),a._v(" "),v("h3",{attrs:{id:"_6-olap生态系统"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_6-olap生态系统"}},[a._v("#")]),a._v(" 6.OLAP生态系统")]),a._v(" "),v("p",[a._v("（1）OLAP-Kylin\n（2）OLAP-Presto\n（3）OLAP-Druid\n（4）OLAP-Impala\n（5）OLAP-ClickHouse\n（6）OLAP-Phoenix、Kudu、Doirs等等")]),a._v(" "),v("h3",{attrs:{id:"_7-稳健架构设计"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_7-稳健架构设计"}},[a._v("#")]),a._v(" 7.稳健架构设计")]),a._v(" "),v("ol",[v("li",[a._v("离线数仓架构方法论")]),a._v(" "),v("li",[a._v("实时数仓架构方法论")]),a._v(" "),v("li",[a._v("数据治理-数据质量管理")]),a._v(" "),v("li",[a._v("数据治理-元数据管理")]),a._v(" "),v("li",[a._v("数据治理-数据安全管理")]),a._v(" "),v("li",[a._v("Kerberos")]),a._v(" "),v("li",[a._v("数据中台构建方法论")]),a._v(" "),v("li",[a._v("可视化")])]),a._v(" "),v("h3",{attrs:{id:"_8-集群调度体系"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_8-集群调度体系"}},[a._v("#")]),a._v(" 8.集群调度体系")]),a._v(" "),v("ol",[v("li",[a._v("分布式资源调度 Yarn")]),a._v(" "),v("li",[a._v("任务流调度 oozie")]),a._v(" "),v("li",[a._v("任务流调度 Azkaban")]),a._v(" "),v("li",[a._v("任务流调度 Airflow")]),a._v(" "),v("li",[a._v("集群管理平台 cloudera manager")]),a._v(" "),v("li",[a._v("集群管理平台 Ambari")])]),a._v(" "),v("h3",{attrs:{id:"_9-数据挖掘体系相关"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_9-数据挖掘体系相关"}},[a._v("#")]),a._v(" 9.数据挖掘体系相关")]),a._v(" "),v("ol",[v("li",[a._v("python")]),a._v(" "),v("li",[a._v("多元线性回归")]),a._v(" "),v("li",[a._v("贝叶斯算法")]),a._v(" "),v("li",[a._v("KNN算法")]),a._v(" "),v("li",[a._v("KMeans算法")]),a._v(" "),v("li",[a._v("KMeans++")]),a._v(" "),v("li",[a._v("TF-IDF")]),a._v(" "),v("li",[a._v("逻辑回归")]),a._v(" "),v("li",[a._v("决策树")]),a._v(" "),v("li",[a._v("随机森林等等")])]),a._v(" "),v("h2",{attrs:{id:"_4-大数据架构演变"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_4-大数据架构演变"}},[a._v("#")]),a._v(" 4.大数据架构演变")]),a._v(" "),v("h3",{attrs:{id:"_1-lambda架构-离线处理-实时链路"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_1-lambda架构-离线处理-实时链路"}},[a._v("#")]),a._v(" 1.Lambda架构（离线处理+实时链路）")]),a._v(" "),v("img",{attrs:{src:a.$withBase("/img/bigdata/传统离线架构.jpg"),alt:"传统离线架构"}}),a._v(" "),v("img",{attrs:{src:a.$withBase("/img/bigdata/Lambda架构-传统实时开发.jpg"),alt:"Lambda架构-传统实时开发"}}),a._v(" "),v("h4",{attrs:{id:"_1-离线处理"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_1-离线处理"}},[a._v("#")]),a._v(" 1.离线处理")]),a._v(" "),v("ul",[v("li",[a._v("数据采集：Sqoop、DataX")]),a._v(" "),v("li",[a._v("基于Hive的离线数仓：ODS、DWD、DWM、DWS、DM")]),a._v(" "),v("li",[a._v("离线结果查询：Impala、Mysql （T+1）")])]),a._v(" "),v("h4",{attrs:{id:"_2-实时处理"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_2-实时处理"}},[a._v("#")]),a._v(" 2.实时处理")]),a._v(" "),v("ul",[v("li",[a._v("数据采集：Flume、Canal、Maxwell")]),a._v(" "),v("li",[a._v("实时计算链路：Kafka、SparkStream、Flink")]),a._v(" "),v("li",[a._v("实时结果存储：HBase、Redis、Mysql")])]),a._v(" "),v("h4",{attrs:{id:"_3-缺点"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_3-缺点"}},[a._v("#")]),a._v(" 3. 缺点")]),a._v(" "),v("ul",[v("li",[a._v("实时链路烟囱式开发，数据不能复用")])]),a._v(" "),v("h3",{attrs:{id:"_2-lambda架构-离线数仓-实时数仓"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_2-lambda架构-离线数仓-实时数仓"}},[a._v("#")]),a._v(" 2.Lambda架构（离线数仓+实时数仓）")]),a._v(" "),v("img",{attrs:{src:a.$withBase("/img/bigdata/Lambda架构-实时数仓.jpg"),alt:"Lambda架构-实时数仓"}}),a._v(" "),v("h4",{attrs:{id:"_1-离线处理-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_1-离线处理-2"}},[a._v("#")]),a._v(" 1.离线处理")]),a._v(" "),v("ul",[v("li",[a._v("数据采集：Sqoop、DataX")]),a._v(" "),v("li",[a._v("基于Hive的离线数仓：ODS、DWD、DWM、DWS、DM")]),a._v(" "),v("li",[a._v("离线结果查询：Impala、Mysql （T+1）")])]),a._v(" "),v("h4",{attrs:{id:"_2-实时处理-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_2-实时处理-2"}},[a._v("#")]),a._v(" 2.实时处理")]),a._v(" "),v("ul",[v("li",[a._v("数据采集：Flume、Canal、Maxwell")]),a._v(" "),v("li",[a._v("实时数据仓库：ODS+Kafka、DWD+Kafka、DWM+Kafka、DWS+Kafka、SparkStream、DM+HBase或Redis或Mysql或ES")])]),a._v(" "),v("h4",{attrs:{id:"_3-缺点-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_3-缺点-2"}},[a._v("#")]),a._v(" 3.缺点")]),a._v(" "),v("ul",[v("li",[a._v("同样需求需要开发两套一样的代码")]),a._v(" "),v("li",[a._v("集群资源使用增多")]),a._v(" "),v("li",[a._v("计算结果不一致，以离线结果为主")]),a._v(" "),v("li",[a._v("批量计算T+1可能计算不完，资源不变，数据量越来越大")]),a._v(" "),v("li",[a._v("服务器存储大")])]),a._v(" "),v("h3",{attrs:{id:"_3-kappa架构"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_3-kappa架构"}},[a._v("#")]),a._v(" 3.Kappa架构")]),a._v(" "),v("img",{attrs:{src:a.$withBase("/img/bigdata/Kappa架构.jpg"),alt:"Kappa架构"}}),a._v(" "),v("h4",{attrs:{id:"_1-实时数仓"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_1-实时数仓"}},[a._v("#")]),a._v(" 1.实时数仓")]),a._v(" "),v("ul",[v("li",[a._v("数据采集：Flume、Canal、Maxwell")]),a._v(" "),v("li",[a._v("实时数据仓库：ODS+Kafka、DWD+Kafka、DWM+Kafka、DWS+Kafka、SparkStream、DM+HBase或Redis或Mysql或ES")])]),a._v(" "),v("h4",{attrs:{id:"_2-缺点"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_2-缺点"}},[a._v("#")]),a._v(" 2.缺点")]),a._v(" "),v("ul",[v("li",[a._v("Kafka无法支撑海量数据存储")]),a._v(" "),v("li",[a._v("Kafka不支持SQL查询，无法支持高效的OLAP")]),a._v(" "),v("li",[a._v("无法复用数据血缘管理体系（错误溯源）")]),a._v(" "),v("li",[a._v("为保证数仓计算数据的正确性，需要对数据进行更新，Kafka不支持update、upsert")])]),a._v(" "),v("h3",{attrs:{id:"_4-架构选择"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_4-架构选择"}},[a._v("#")]),a._v(" 4.架构选择")]),a._v(" "),v("h4",{attrs:{id:"_1-公司刚上大数据或者公司业务没有实时场景"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_1-公司刚上大数据或者公司业务没有实时场景"}},[a._v("#")]),a._v(" 1.公司刚上大数据或者公司业务没有实时场景")]),a._v(" "),v("p",[a._v("选择传统离线大数据架构")]),a._v(" "),v("h4",{attrs:{id:"_2-公司离线业务多-实时业务少"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_2-公司离线业务多-实时业务少"}},[a._v("#")]),a._v(" 2.公司离线业务多，实时业务少")]),a._v(" "),v("p",[a._v("离线数仓+实时链路的Lambda架构")]),a._v(" "),v("h4",{attrs:{id:"_3-公司离线业务和实时业务都比较多"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_3-公司离线业务和实时业务都比较多"}},[a._v("#")]),a._v(" 3.公司离线业务和实时业务都比较多")]),a._v(" "),v("p",[a._v("离线数仓+实时数仓的Lambda架构")]),a._v(" "),v("h4",{attrs:{id:"_4-公司实时业务多-离线业务相对少"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_4-公司实时业务多-离线业务相对少"}},[a._v("#")]),a._v(" 4.公司实时业务多，离线业务相对少")]),a._v(" "),v("p",[a._v("Kappa纯实时数仓架构")]),a._v(" "),v("blockquote",[v("p",[a._v("绝大多数公司采用Lambda架构")]),a._v(" "),v("p",[a._v("互联网公司实时业务多混合架构（实时业务采用Kappa，关键核心业务使用离线全量计算方式Lambda）")])]),a._v(" "),v("h4",{attrs:{id:"_5-一些互联网公司的架构示例"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_5-一些互联网公司的架构示例"}},[a._v("#")]),a._v(" 5.一些互联网公司的架构示例")]),a._v(" "),v("img",{attrs:{src:a.$withBase("/img/bigdata/滴滴架构.jpg"),alt:"滴滴架构"}}),a._v(" "),v("img",{attrs:{src:a.$withBase("/img/bigdata/顺丰实时数仓架构.jpg"),alt:"顺丰实时数仓架构"}}),a._v(" "),v("img",{attrs:{src:a.$withBase("/img/bigdata/网易业务链.jpg"),alt:"网易业务链"}}),a._v(" "),v("img",{attrs:{src:a.$withBase("/img/bigdata/腾讯原有架构.jpg"),alt:"腾讯原有架构"}}),a._v(" "),v("img",{attrs:{src:a.$withBase("/img/bigdata/腾讯改造后架构.jpg"),alt:"腾讯改造后架构"}}),a._v(" "),v("h3",{attrs:{id:"_5-湖仓一体实时数据架构"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_5-湖仓一体实时数据架构"}},[a._v("#")]),a._v(" 5.湖仓一体实时数据架构")]),a._v(" "),v("img",{attrs:{src:a.$withBase("/img/bigdata/湖仓一体实时数仓.jpg"),alt:"湖仓一体实时数仓"}}),a._v(" "),v("blockquote",[v("p",[a._v("批流一体：既可以进行批处理，又可以进行流处理")]),a._v(" "),v("p",[a._v("1.架构角度")]),a._v(" "),v("p",[a._v("2.计算框架处理角度")]),a._v(" "),v("p",[a._v("3.SQL支持角度")]),a._v(" "),v("p",[a._v("4.存储层面")])]),a._v(" "),v("h4",{attrs:{id:"_1-解决了以上架构的痛点"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_1-解决了以上架构的痛点"}},[a._v("#")]),a._v(" 1.解决了以上架构的痛点：")]),a._v(" "),v("ul",[v("li",[a._v("存储统一")]),a._v(" "),v("li",[a._v("Kafka存储量小的问题")]),a._v(" "),v("li",[a._v("任意分层都可以进行OLAP数据分析")]),a._v(" "),v("li",[a._v("复用同一套相同的血缘关系")]),a._v(" "),v("li",[a._v("实时数据更新")])]),a._v(" "),v("h4",{attrs:{id:"_2-缺点-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_2-缺点-2"}},[a._v("#")]),a._v(" 2.缺点")]),a._v(" "),v("ul",[v("li",[a._v("技术较新，存在较多的bug")]),a._v(" "),v("li",[a._v("数据湖技术数据存储速度没有Kafka快")])]),a._v(" "),v("h2",{attrs:{id:"_5-hadoop"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_5-hadoop"}},[a._v("#")]),a._v(" 5.Hadoop")]),a._v(" "),v("p",[a._v("海量数据的分布式存储和计算平台，包含：")]),a._v(" "),v("ul",[v("li",[a._v("Hadoop Common：基础组件，包括数据IO，数据类型，序列化，安全等等")]),a._v(" "),v("li",[a._v("Hadoop Distributed File System （HDFS）：分布式存储数据的文件管理系统，是在Linux的文件系统之上套了一层管理文件的软件技术")]),a._v(" "),v("li",[a._v("Hadoop Yarn：作业调度和资源管理平台")]),a._v(" "),v("li",[a._v("Hadoop MapReduce：分布式计算模型，适合批处理的计算任务")])]),a._v(" "),v("blockquote",[v("p",[a._v("批处理与流处理的区别：")]),a._v(" "),v("p",[a._v("批处理：有界、持久、大量，非常适合需要访问全套记录才能完成的计算工作，一般用于离线统计。")]),a._v(" "),v("p",[a._v("流处理：无界、实时，无需针对整个数据集执行操作，而是对通过系统传输的每个数据项执行操作，一般用于实时统计。")]),a._v(" "),v("p",[a._v("spark与flink的区别：")]),a._v(" "),v("p",[a._v("spark：一切都是由批次组成的，离线数据是一个大批次，而实时数据是有一个一个无限的小批次组成的。")]),a._v(" "),v("p",[a._v("flink：一切都是由流组成的，离线数据是一个有界的流，而实时数据是一个没有界限的流，这就是所谓的有界流和无界流。")])]),a._v(" "),v("h3",{attrs:{id:"_1-hdfs"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_1-hdfs"}},[a._v("#")]),a._v(" 1.HDFS")]),a._v(" "),v("h4",{attrs:{id:"_1-存储模型"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_1-存储模型"}},[a._v("#")]),a._v(" 1.存储模型")]),a._v(" "),v("ul",[v("li",[a._v("文件线性按字节切割成块（block），具有offset、id")]),a._v(" "),v("li",[a._v("文件与文件的block大小可以不一样")]),a._v(" "),v("li",[a._v("一个文件除最后一个block，其他block大小一致")]),a._v(" "),v("li",[a._v("block的大小依据硬件的I/O特性调整")]),a._v(" "),v("li",[a._v("block被分散存放在集群的节点中，具有location（块在哪）")]),a._v(" "),v("li",[a._v("block具有副本（replication），没有主从的概念，副本不能出现在同一个节点上")]),a._v(" "),v("li",[a._v("副本是满足可靠性和性能的关键")]),a._v(" "),v("li",[a._v("文件上传可以指定block大小和副本数，上传后只能修改副本数")]),a._v(" "),v("li",[a._v("一次写入多次读取，不支持修改")]),a._v(" "),v("li",[a._v("支持追加数据")])]),a._v(" "),v("h4",{attrs:{id:"_2-架构设计"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_2-架构设计"}},[a._v("#")]),a._v(" 2.架构设计")]),a._v(" "),v("ul",[v("li",[a._v("HDFS时一个主从架构")]),a._v(" "),v("li",[a._v("有一个NameNode和一些DataNode组成")]),a._v(" "),v("li",[a._v("面向文件包含：文件数据（data）和文件元数据（medadata）")]),a._v(" "),v("li",[a._v("NameNode负责存储和管理文件元数据，并维护了一个层次型的文件目录树")]),a._v(" "),v("li",[a._v("DataNode负责存储文件数据（block），并提供block的读写")]),a._v(" "),v("li",[a._v("DataNode与NameNode维持心跳，并汇报自己持有的block信息")]),a._v(" "),v("li",[a._v("Client和NameNode交互文件元数据和DataNode交互文件block数据")])]),a._v(" "),v("h4",{attrs:{id:"_3-角色功能"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_3-角色功能"}},[a._v("#")]),a._v(" 3.角色功能")]),a._v(" "),v("p",[a._v("角色即JVM进程，NameNode、DataNode都是一个JVM进程")]),a._v(" "),v("p",[v("strong",[a._v("NameNode：")])]),a._v(" "),v("ul",[v("li",[a._v("完全基于内存存储文件元数据、目录结构、文件block的映射")]),a._v(" "),v("li",[a._v("需要持久化方案保证数据可靠性")]),a._v(" "),v("li",[a._v("提供副本放置策略")])]),a._v(" "),v("p",[v("strong",[a._v("DataNode：")])]),a._v(" "),v("ul",[v("li",[a._v("基于本地磁盘存储block")]),a._v(" "),v("li",[a._v("并保存block的校验和保证数据block的可靠性")]),a._v(" "),v("li",[a._v("与NameNode保持心跳、汇报block列表状态")])]),a._v(" "),v("h4",{attrs:{id:"_4-元数据持久化"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_4-元数据持久化"}},[a._v("#")]),a._v(" 4.元数据持久化")]),a._v(" "),v("ul",[v("li",[v("p",[a._v("任何对文件系统元数据产生修改的操作，NameNode都会使用一种成为EditLog的事务日志记录下来（记录增删改操作）")])]),a._v(" "),v("li",[v("p",[a._v("使用FsImage存储内存所有的元数据状态（快照/镜像，间隔发生，内存全量数据基于某个时间点做的向磁盘的溢写，瓶颈在I/O）")])]),a._v(" "),v("li",[v("p",[a._v("使用本地磁盘保存EditLog和FsImage")])]),a._v(" "),v("li",[v("p",[a._v("EditLog具有完整性，数据丢失少，但恢复速度慢，并有体积膨胀风险")])]),a._v(" "),v("li",[v("p",[a._v("FsImage具有恢复速度快，体积与内存数据相当，但不能实时保存，数据丢失多")])]),a._v(" "),v("li",[v("p",[a._v("NameNode使用了FsImage+EditLog整合的方案：")]),a._v(" "),v("ul",[v("li",[a._v("滚定将增量的EditLog更新到FsImage，以保证更新近时点的FsImage和更小的EditLog体积\n"),v("ul",[v("li",[a._v("最近时点的FI + 增量的EL")]),a._v(" "),v("li",[a._v("10点  ===>  9点的FI  + 9点到10点的EL，下次开机时，加载FI，加载EL，内存就得到了上次关机前全量的数据")])])])])])]),a._v(" "),v("h4",{attrs:{id:"_5-安全模式"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_5-安全模式"}},[a._v("#")]),a._v(" 5.安全模式")]),a._v(" "),v("ul",[v("li",[a._v("HDFS搭建时会格式化，格式化操作会产生一个空的FsImage")]),a._v(" "),v("li",[a._v("当NameNode启动时，它从硬盘中读取EditLog和FsImage")]),a._v(" "),v("li",[a._v("将所有EditLog中的事务作用在内存中的FsImage上")]),a._v(" "),v("li",[a._v("并将这个新版本的FsImage从内存中保存到本地磁盘上")]),a._v(" "),v("li",[a._v("然后删除旧的EditLog，因为这个旧的EditLog的事务都已经作用在FsImage上了")]),a._v(" "),v("li",[a._v("NameNode启动后会进入一个称为安全模式的特殊状态")]),a._v(" "),v("li",[a._v("处于安全模式的NameNode是不会进行数据块的复制的")]),a._v(" "),v("li",[a._v("NameNode从所有的DataNode接收心跳信号和状态报告")]),a._v(" "),v("li",[a._v("每当NameNode检测确认某个数据块的副本数目达到这个最小值，那么该数据块就会被认为时副本安全的（safely replicated）")]),a._v(" "),v("li",[a._v("在一定百分比（可配）的数据块被NameNode检测确认是安全之后（加上一个额外的30秒等待时间），NameNode将退出安全模式状态")]),a._v(" "),v("li",[a._v("接下来它会确定还有那些数据块的副本没有到达指定数目，并将这些数据块复制到其他DataNode上")])]),a._v(" "),v("blockquote",[v("p",[a._v("​     NameNode存元数据，文件属性、每个块在哪个DataNode上。在持久化的时候，文件属性会持久化，但是文件的每一个块不会持久化，恢复的时候，NameNode会丢失块的位置信息，需要等DataNode与NameNode建立心跳，汇报块的信息。")])]),a._v(" "),v("h4",{attrs:{id:"_6-hdfs中的snn-secondarynamenode"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_6-hdfs中的snn-secondarynamenode"}},[a._v("#")]),a._v(" 6.HDFS中的SNN（SecondaryNameNode）")]),a._v(" "),v("img",{attrs:{src:a.$withBase("/img/bigdata/SNN.jpg"),alt:"SNN"}}),a._v(" "),v("ul",[v("li",[a._v("在非Ha模式下（非高可用，即只有一个NameNode，企业一般不会用这种模式，NameNode一旦挂掉，整个服务就会下线），SNN一般是独立的节点，周期完成对NameNode的EditLog向FsImage合并，减少EditLog大小，减少SNN启动时间")]),a._v(" "),v("li",[a._v("根据配置文件设置的时间间隔fs.checkpoint.period 默认是3600秒")]),a._v(" "),v("li",[a._v("根据配置文件设置的edits log大小 fs.checkpoint.size 规定edits文件的最大值默认是64MB")])]),a._v(" "),v("h4",{attrs:{id:"_7-block的副本放置策略"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_7-block的副本放置策略"}},[a._v("#")]),a._v(" 7.Block的副本放置策略")]),a._v(" "),v("ul",[v("li",[a._v("第一个副本：放置在上传文件的DataNode；如果是集群外提交，则随机挑选一台磁盘不太满，CPU不太忙的节点。")]),a._v(" "),v("li",[a._v("第二个副本：放置在与第一个副本不同的机架的节点上。")]),a._v(" "),v("li",[a._v("第三个副本：与第二个副本相同机架的节点（在同一个交换机下，降低成本）。")]),a._v(" "),v("li",[a._v("更多副本：随机节点。（机架即机房放置服务器的架子，同一个机架上的服务器有自己的交换机和ups电源）")])]),a._v(" "),v("h4",{attrs:{id:"_8-hdfs读写流程"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_8-hdfs读写流程"}},[a._v("#")]),a._v(" 8.HDFS读写流程")]),a._v(" "),v("img",{attrs:{src:a.$withBase("/img/bigdata/HDFS写流程.jpg"),alt:"HDFS写流程"}}),a._v(" "),v("h5",{attrs:{id:"写流程"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#写流程"}},[a._v("#")]),a._v(" 写流程")]),a._v(" "),v("ul",[v("li",[a._v("Client和NameNode连接创建文件元数据")]),a._v(" "),v("li",[a._v("NameNode判定元数据是否有效")]),a._v(" "),v("li",[a._v("NameNode处发副本放置策略，返回一个有序的DataNode列表")]),a._v(" "),v("li",[a._v("Client和DataNode建立Pipeline连接")]),a._v(" "),v("li",[a._v("Client将块切分成packet（64kb），并使用chunk（512b）+chunksum（4b）填充")]),a._v(" "),v("li",[a._v("Client将packet放入发送队列dataqueue中，并向第一个DataNode发送")]),a._v(" "),v("li",[a._v("第一个DataNode收到packet后本地保存并发送给第二个DataNode")]),a._v(" "),v("li",[a._v("第二个DataNode收到packet后本地保存并发送给第三个DataNode")]),a._v(" "),v("li",[a._v("这一个过程中，上游节点同时发送下一个packet（生活中类比工厂的流水线，结论：流式其实也是变种的并行计算）")]),a._v(" "),v("li",[a._v("HDFS使用这种传输方式，副本数对于Client是透明的")]),a._v(" "),v("li",[a._v("当block传输完成，DataNode们各自向NameNode汇报，同时Client继续传输下一个block")]),a._v(" "),v("li",[a._v("所以，Client的传输和block的汇报也是并行的")])]),a._v(" "),v("img",{attrs:{src:a.$withBase("/img/bigdata/HDFS读流程.jpg"),alt:"HDFS读流程"}}),a._v(" "),v("h5",{attrs:{id:"读流程"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#读流程"}},[a._v("#")]),a._v(" 读流程")]),a._v(" "),v("ul",[v("li",[a._v("为了降低整体的带宽消耗和读取延时，HDFS会尽量让读取程序读取离它最近的副本")]),a._v(" "),v("li",[a._v("如果在读取程序的同一个机架上有一个副本，那么就读取该副本")]),a._v(" "),v("li",[a._v("如果一个HDFS集群跨越多个数据中心，那么客户端也将首先读取本地的数据中心的副本")]),a._v(" "),v("li",[a._v("语义：下载一个文件：\n"),v("ul",[v("li",[a._v("Client与NameNode交互文件元数据获取fileBlockLocation")]),a._v(" "),v("li",[a._v("NameNode会按距离策略排序返回")]),a._v(" "),v("li",[a._v("Client尝试下载block并校验数据完整性")])])]),a._v(" "),v("li",[a._v("语义：下载一个文件其实是获取文件的所有block元数据，那么子集获取某些block应该成立\n"),v("ul",[v("li",[a._v("HDFS支持Client给出文件的offset自定义连接哪些block的DataNode，自定义获取数据")]),a._v(" "),v("li",[a._v("这个是支持计算层的分治，并行计算的核心")])])])]),a._v(" "),v("h2",{attrs:{id:"_6-数据湖"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_6-数据湖"}},[a._v("#")]),a._v(" 6.数据湖")]),a._v(" "),v("p",[a._v("数据湖就是集中式的数据存储库，可以存储各自数据格式数据，例如：非机构化数据、结构化数据、文本、视频......（待续）")])])}),[],!1,null,null,null);_.default=i.exports}}]);